
@article{kushnareva_artificial_2021,
	title = {Artificial {Text} {Detection} via {Examining} the {Topology} of {Attention} {Maps}},
	url = {http://arxiv.org/abs/2109.04825},
	abstract = {The impressive capabilities of recent generative models to create texts that are challenging to distinguish from the human-written ones can be misused for generating fake news, product reviews, and even abusive content. Despite the prominent performance of existing methods for artificial text detection, they still lack interpretability and robustness towards unseen models. To this end, we propose three novel types of interpretable topological features for this task based on Topological Data Analysis (TDA) which is currently understudied in the field of NLP. We empirically show that the features derived from the BERT model outperform count- and neural-based baselines up to 10{\textbackslash}\% on three common datasets, and tend to be the most robust towards unseen GPT-style generation models as opposed to existing methods. The probing analysis of the features reveals their sensitivity to the surface and syntactic properties. The results demonstrate that TDA is a promising line with respect to NLP tasks, specifically the ones that incorporate surface and structural information.},
	urldate = {2022-03-09},
	journal = {arXiv:2109.04825 [cs]},
	author = {Kushnareva, Laida and Cherniavskii, Daniil and Mikhailov, Vladislav and Artemova, Ekaterina and Barannikov, Serguei and Bernstein, Alexander and Piontkovskaya, Irina and Piontkovski, Dmitri and Burnaev, Evgeny},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.04825},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Accepted to EMNLP 2021},
	file = {arXiv Fulltext PDF:C\:\\Users\\rebel\\Zotero\\storage\\RGCCZ928\\Kushnareva et al. - 2021 - Artificial Text Detection via Examining the Topolo.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\rebel\\Zotero\\storage\\5TZCLL2Q\\2109.html:text/html},
}

@inproceedings{uchendu_authorship_2020,
	address = {Online},
	title = {Authorship {Attribution} for {Neural} {Text} {Generation}},
	url = {https://aclanthology.org/2020.emnlp-main.673},
	doi = {10.18653/v1/2020.emnlp-main.673},
	abstract = {In recent years, the task of generating realistic short and long texts have made tremendous advancements. In particular, several recently proposed neural network-based language models have demonstrated their astonishing capabilities to generate texts that are challenging to distinguish from human-written texts with the naked eye. Despite many benefits and utilities of such neural methods, in some applications, being able to tell the “author” of a text in question becomes critically important. In this work, in the context of this Turing Test, we investigate the so-called authorship attribution problem in three versions: (1) given two texts T1 and T2, are both generated by the same method or not? (2) is the given text T written by a human or machine? (3) given a text T and k candidate neural methods, can we single out the method (among k alternatives) that generated T? Against one humanwritten and eight machine-generated texts (i.e., CTRL, GPT, GPT2, GROVER, XLM, XLNET, PPLM, FAIR), we empirically experiment with the performance of various models in three problems. By and large, we find that most generators still generate texts significantly different from human-written ones, thereby making three problems easier to solve. However, the qualities of texts generated by GPT2, GROVER, and FAIR are better, often confusing machine classifiers in solving three problems. All codes and datasets of our experiments are available at: https://bit.ly/ 302zWdz},
	urldate = {2022-03-09},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Uchendu, Adaku and Le, Thai and Shu, Kai and Lee, Dongwon},
	month = nov,
	year = {2020},
	pages = {8384--8395},
	file = {Full Text PDF:C\:\\Users\\rebel\\Zotero\\storage\\NB3KR7GQ\\Uchendu et al. - 2020 - Authorship Attribution for Neural Text Generation.pdf:application/pdf},
}

@article{bakhtin_real_2019,
	title = {Real or {Fake}? {Learning} to {Discriminate} {Machine} from {Human} {Generated} {Text}},
	shorttitle = {Real or {Fake}?},
	url = {http://arxiv.org/abs/1906.03351},
	abstract = {Energy-based models (EBMs), a.k.a. un-normalized models, have had recent successes in continuous spaces. However, they have not been successfully applied to model text sequences. While decreasing the energy at training samples is straightforward, mining (negative) samples where the energy should be increased is difficult. In part, this is because standard gradient-based methods are not readily applicable when the input is high-dimensional and discrete. Here, we side-step this issue by generating negatives using pre-trained auto-regressive language models. The EBM then works in the residual of the language model; and is trained to discriminate real text from text generated by the auto-regressive models. We investigate the generalization ability of residual EBMs, a pre-requisite for using them in other applications. We extensively analyze generalization for the task of classifying whether an input is machine or human generated, a natural task given the training loss and how we mine negatives. Overall, we observe that EBMs can generalize remarkably well to changes in the architecture of the generators producing negatives. However, EBMs exhibit more sensitivity to the training set used by such generators.},
	urldate = {2022-03-09},
	journal = {arXiv:1906.03351 [cs, stat]},
	author = {Bakhtin, Anton and Gross, Sam and Ott, Myle and Deng, Yuntian and Ranzato, Marc'Aurelio and Szlam, Arthur},
	month = nov,
	year = {2019},
	note = {arXiv: 1906.03351},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\rebel\\Zotero\\storage\\LGNL7B7L\\Bakhtin et al. - 2019 - Real or Fake Learning to Discriminate Machine fro.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\rebel\\Zotero\\storage\\BNTL2IXP\\1906.html:text/html},
}

@misc{noauthor_fake_nodate,
	title = {Fake {Text} {Detecting} with {Machine} {Learning}: {Trump} {Case} {Study} {\textbar} {DAIN} {Studios}},
	shorttitle = {Fake {Text} {Detecting} with {Machine} {Learning}},
	url = {https://dainstudios.com/insights/fake-text-detecting-with-machine-learning-trump-case-study/},
	abstract = {Twitter bots and fake social media accounts made the headlines back in 2016 when they were proven to have shifted the US election results. This year, a new},
	language = {en-US},
	urldate = {2022-03-09},
	note = {Section: News},
	file = {Snapshot:C\:\\Users\\rebel\\Zotero\\storage\\PFTM6CVB\\fake-text-detecting-with-machine-learning-trump-case-study.html:text/html},
}

@article{fagni_tweepfake_2021,
	title = {{TweepFake}: about {Detecting} {Deepfake} {Tweets}},
	volume = {16},
	issn = {1932-6203},
	shorttitle = {{TweepFake}},
	url = {http://arxiv.org/abs/2008.00036},
	doi = {10.1371/journal.pone.0251415},
	abstract = {The recent advances in language modeling significantly improved the generative capabilities of deep neural models: in 2019 OpenAI released GPT-2, a pre-trained language model that can autonomously generate coherent, non-trivial and human-like text samples. Since then, ever more powerful text generative models have been developed. Adversaries can exploit these tremendous generative capabilities to enhance social bots that will have the ability to write plausible deepfake messages, hoping to contaminate public debate. To prevent this, it is crucial to develop deepfake social media messages detection systems. However, to the best of our knowledge no one has ever addressed the detection of machine-generated texts on social networks like Twitter or Facebook. With the aim of helping the research in this detection field, we collected the first dataset of {\textbackslash}real deepfake tweets, TweepFake. It is real in the sense that each deepfake tweet was actually posted on Twitter. We collected tweets from a total of 23 bots, imitating 17 human accounts. The bots are based on various generation techniques, i.e., Markov Chains, RNN, RNN+Markov, LSTM, GPT-2. We also randomly selected tweets from the humans imitated by the bots to have an overall balanced dataset of 25,572 tweets (half human and half bots generated). The dataset is publicly available on Kaggle. Lastly, we evaluated 13 deepfake text detection methods (based on various state-of-the-art approaches) to both demonstrate the challenges that Tweepfake poses and create a solid baseline of detection techniques. We hope that TweepFake can offer the opportunity to tackle the deepfake detection on social media messages as well.},
	number = {5},
	urldate = {2022-03-09},
	journal = {PLOS ONE},
	author = {Fagni, Tiziano and Falchi, Fabrizio and Gambini, Margherita and Martella, Antonio and Tesconi, Maurizio},
	month = may,
	year = {2021},
	note = {arXiv: 2008.00036},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	pages = {e0251415},
	file = {arXiv Fulltext PDF:C\:\\Users\\rebel\\Zotero\\storage\\PAXB2RIQ\\Fagni et al. - 2021 - TweepFake about Detecting Deepfake Tweets.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\rebel\\Zotero\\storage\\2W38M5MQ\\2008.html:text/html},
}

@article{bahri_generative_2020,
	title = {Generative {Models} are {Unsupervised} {Predictors} of {Page} {Quality}: {A} {Colossal}-{Scale} {Study}},
	shorttitle = {Generative {Models} are {Unsupervised} {Predictors} of {Page} {Quality}},
	url = {http://arxiv.org/abs/2008.13533},
	abstract = {Large generative language models such as GPT-2 are well-known for their ability to generate text as well as their utility in supervised downstream tasks via fine-tuning. Our work is twofold: firstly we demonstrate via human evaluation that classifiers trained to discriminate between human and machine-generated text emerge as unsupervised predictors of "page quality", able to detect low quality content without any training. This enables fast bootstrapping of quality indicators in a low-resource setting. Secondly, curious to understand the prevalence and nature of low quality pages in the wild, we conduct extensive qualitative and quantitative analysis over 500 million web articles, making this the largest-scale study ever conducted on the topic.},
	urldate = {2022-03-09},
	journal = {arXiv:2008.13533 [cs, stat]},
	author = {Bahri, Dara and Tay, Yi and Zheng, Che and Metzler, Donald and Brunk, Cliff and Tomkins, Andrew},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.13533},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\rebel\\Zotero\\storage\\KHDRUBAN\\Bahri et al. - 2020 - Generative Models are Unsupervised Predictors of P.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\rebel\\Zotero\\storage\\46SPMY8Y\\2008.html:text/html},
}

@article{adelani_generating_2019,
	title = {Generating {Sentiment}-{Preserving} {Fake} {Online} {Reviews} {Using} {Neural} {Language} {Models} and {Their} {Human}- and {Machine}-based {Detection}},
	url = {http://arxiv.org/abs/1907.09177},
	abstract = {Advanced neural language models (NLMs) are widely used in sequence generation tasks because they are able to produce fluent and meaningful sentences. They can also be used to generate fake reviews, which can then be used to attack online review systems and influence the buying decisions of online shoppers. To perform such attacks, it is necessary for experts to train a tailored LM for a specific topic. In this work, we show that a low-skilled threat model can be built just by combining publicly available LMs and show that the produced fake reviews can fool both humans and machines. In particular, we use the GPT-2 NLM to generate a large number of high-quality reviews based on a review with the desired sentiment and then using a BERT based text classifier (with accuracy of 96\%) to filter out reviews with undesired sentiments. Because none of the words in the review are modified, fluent samples like the training data can be generated from the learned distribution. A subjective evaluation with 80 participants demonstrated that this simple method can produce reviews that are as fluent as those written by people. It also showed that the participants tended to distinguish fake reviews randomly. Three countermeasures, Grover, GLTR, and OpenAI GPT-2 detector, were found to be difficult to accurately detect fake review.},
	urldate = {2022-03-09},
	journal = {arXiv:1907.09177 [cs]},
	author = {Adelani, David Ifeoluwa and Mai, Haotian and Fang, Fuming and Nguyen, Huy H. and Yamagishi, Junichi and Echizen, Isao},
	month = dec,
	year = {2019},
	note = {arXiv: 1907.09177},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning, Computer Science - Cryptography and Security},
	annote = {Comment: The 34-th International Conference on Advanced Information Networking and Applications (AINA-2020)},
	file = {arXiv Fulltext PDF:C\:\\Users\\rebel\\Zotero\\storage\\72WANPVS\\Adelani et al. - 2019 - Generating Sentiment-Preserving Fake Online Review.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\rebel\\Zotero\\storage\\YJ36R59Q\\1907.html:text/html},
}

@inproceedings{manjavacas_assessing_2017,
	address = {Copenhagen, Denmark},
	title = {Assessing the {Stylistic} {Properties} of {Neurally} {Generated} {Text} in {Authorship} {Attribution}},
	url = {https://aclanthology.org/W17-4914},
	doi = {10.18653/v1/W17-4914},
	abstract = {Recent applications of neural language models have led to an increased interest in the automatic generation of natural language. However impressive, the evaluation of neurally generated text has so far remained rather informal and anecdotal. Here, we present an attempt at the systematic assessment of one aspect of the quality of neurally generated text. We focus on a specific aspect of neural language generation: its ability to reproduce authorial writing styles. Using established models for authorship attribution, we empirically assess the stylistic qualities of neurally generated text. In comparison to conventional language models, neural models generate fuzzier text, that is relatively harder to attribute correctly. Nevertheless, our results also suggest that neurally generated text offers more valuable perspectives for the augmentation of training data.},
	urldate = {2022-03-09},
	booktitle = {Proceedings of the {Workshop} on {Stylistic} {Variation}},
	publisher = {Association for Computational Linguistics},
	author = {Manjavacas, Enrique and De Gussem, Jeroen and Daelemans, Walter and Kestemont, Mike},
	month = sep,
	year = {2017},
	pages = {116--125},
	file = {Full Text PDF:C\:\\Users\\rebel\\Zotero\\storage\\RQ47SN9X\\Manjavacas et al. - 2017 - Assessing the Stylistic Properties of Neurally Gen.pdf:application/pdf},
}

@article{uchendu_characterizing_2019,
	title = {Characterizing {Man}-made vs. {Machine}-made {Chatbot} {Dialogs}},
	doi = {10.36370/tto.2019.27},
	abstract = {This work attempts to better understand and characterize distinguishing features between man-made and machinemade artifacts, especially chatbot dialog texts, which tend to be short and erroneous, and noted that privacy or entropy related features between two types of texts do not appear to be significantly different. The increasing usage of machine-made artifacts in news and social media can severely exacerbate the problem of false news. While knowing the parts of news content, or embedded images therein, are machine-generated or not helps determine the veracity of news, due to the recent improvement in AI techniques, it has become more difficult to accurately distinguish machine-made artifacts from man-made ones. In this work, therefore, we attempt to better understand and characterize distinguishing features between man-made and machinemade artifacts, especially chatbot dialog texts, which tend to be short and erroneous. Some of the characteristics that we found include: machine-made texts tend to use more words per message, interjections (e.g., hey, hi), use more filler words (e.g., blah, you, and know) and appear to be less confident than man-made texts in their speech. However, we noted that privacy or entropy related features between two types of texts do not appear to be significantly different.},
	journal = {TTO},
	author = {Uchendu, Adaku and Cao, Jeffery and Wang, Qiaozhi and Luo, Bo and Lee, Dongwon},
	year = {2019},
	file = {Full Text:C\:\\Users\\rebel\\Zotero\\storage\\BXQ8ZSY9\\Uchendu et al. - 2019 - Characterizing Man-made vs. Machine-made Chatbot D.pdf:application/pdf},
}

@misc{noauthor_tweepfake_nodate,
	title = {{TweepFake} - {Twitter} deep {Fake} text {Dataset}},
	url = {https://kaggle.com/mtesconi/twitter-deep-fake-text},
	abstract = {Human and machine generated tweets for deep fake social media text detection.},
	language = {en},
	urldate = {2022-03-11},
	file = {Snapshot:C\:\\Users\\rebel\\Zotero\\storage\\UYQ3VM7N\\twitter-deep-fake-text.html:text/html},
}
